# Iroh Custom RPC Implementation Status

## Overview

After determining that `tonic-iroh-transport` was not suitable for our needs, we've implemented a custom RPC protocol over Iroh's QUIC streams. This gives us full control and a clean, simple implementation.

## Architecture

### 1. Protocol Layer (`iroh_protocol.rs`)
- Simple binary protocol with 24-byte headers
- Support for request/response and streaming (future)
- Message types: Request, Response, Error, StreamData, StreamEnd, Ping, Pong
- Built-in request correlation via UUID request IDs
- Maximum message size: 10MB

### 2. Service Framework (`iroh_service.rs`)
- Trait-based service definition (`IrohService`)
- Service registry for managing multiple services
- Server (`IrohRpcServer`) handles incoming connections
- Client (`IrohRpcClient`) with connection pooling
- Clean async/await API

### 3. Example Implementation (`iroh_health_service.rs`)
- Demonstrates how to implement a service
- Health check with node status
- Simple ping/pong for connectivity testing
- Client wrapper for easy usage

## Implementation Status

### âœ… Completed
1. Protocol design and message framing
2. Service trait abstraction
3. Server implementation with service registry
4. Client implementation with connection management
5. Health service as proof of concept
6. Basic integration tests

### ðŸš§ In Progress
1. Integration with IrohPeerConnector
2. Dual transport mode testing

### ðŸ“‹ TODO
1. Implement remaining services (status, VM operations)
2. Add streaming support for Raft messages
3. Create gRPC-to-Iroh adapter for gradual migration
4. Performance benchmarking
5. Add connection health monitoring
6. Implement proper connection pooling with limits

## Protocol Design

### Message Format
```
Header (24 bytes):
- Version (1 byte)
- Message Type (1 byte)  
- Payload Length (4 bytes)
- Request ID (16 bytes)
- Padding (2 bytes)

Payload (variable):
- Serialized with bincode
- Maximum 10MB
```

### RPC Flow
1. Client opens bidirectional QUIC stream
2. Client sends Request message with RpcRequest
3. Server processes and sends Response with RpcResponse
4. Both sides close their streams
5. Connection remains open for reuse

## Usage Example

### Server Side
```rust
// Create server
let server = Arc::new(IrohRpcServer::new(endpoint));

// Register services
server.register_service(health_service).await;
server.register_service(status_service).await;

// Start serving
server.serve().await?;
```

### Client Side
```rust
// Create client
let client = IrohRpcClient::new(endpoint);

// Make RPC call
let response: HealthCheckResponse = client
    .call(node_addr, "health", "check", HealthCheckRequest {})
    .await?;
```

## Advantages Over tonic-iroh-transport

1. **Full Control**: We own the protocol and can optimize
2. **Simplicity**: Much simpler than HTTP/2 + gRPC layers
3. **No Version Conflicts**: Works with our tonic 0.12
4. **Tailored Design**: Optimized for our use case
5. **Learning Value**: Team understands P2P networking

## Performance Considerations

- **Connection Reuse**: Connections are cached and reused
- **Minimal Overhead**: 24-byte header + bincode serialization
- **QUIC Benefits**: Multiplexing, 0-RTT resumption, loss recovery
- **Future Optimizations**: Compression, batching, streaming

## Next Steps

1. **Service Migration**: Implement remaining services
2. **Integration**: Wire up with existing Node infrastructure
3. **Testing**: Comprehensive integration tests
4. **Benchmarking**: Compare performance with gRPC
5. **Production Readiness**: Add monitoring, metrics, error recovery

## Conclusion

Our custom Iroh RPC implementation provides a solid foundation for P2P communication in Blixard. It's simple, efficient, and gives us complete control over the transport layer. The implementation is already functional with basic health checks working end-to-end.